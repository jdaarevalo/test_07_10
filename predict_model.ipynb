{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos los modulos necesarios\n",
    "import pandas as pd\n",
    "\n",
    "import pyspark  #python package\n",
    "import h2o\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# objeto principal o la base a partir de la cual cuelga toda la funcionalidad de Apache Spark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Se trata del context básico de Spark, desde donde se crean el resto de variables \n",
    "# que maneja el framework. Sólo un SparkContext puede estar activo por JVM.\n",
    "from pyspark import SparkContext\n",
    "\n",
    "# el objeto functions del modulo sql define las funciones estándar incorporadas \n",
    "# para trabajar con (valores producidos) columnas.\n",
    "import pyspark.sql.functions as func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new spark session, que sera la base para nuestra aplicacion\n",
    "\n",
    "spark = SparkSession.builder\\\n",
    "                    .appName(\"predict\")\\\n",
    "                    .getOrCreate()\n",
    "\n",
    "#spark sera el punto de entrada para la aplicacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_beneficiario = spark.read.format(\"csv\")\\\n",
    "                            .option(\"header\", \"true\")\\\n",
    "                            .option(\"inferSchema\", \"true\")\\\n",
    "                            .load(\"data/data_test/test_beneficiario.csv\")\n",
    "df_aprovisionadores = spark.read.format(\"csv\")\\\n",
    "                            .option(\"header\", \"true\")\\\n",
    "                            .option(\"inferSchema\", \"true\")\\\n",
    "                            .load(\"data/data_test/test_labels_aprovisionadores.csv\")\n",
    "df_pacientes_aprobados = spark.read.format(\"csv\")\\\n",
    "                            .option(\"header\", \"true\")\\\n",
    "                            .option(\"inferSchema\", \"true\")\\\n",
    "                            .load(\"data/data_test/test_pacientes_aprobados.csv\")\n",
    "df_pacientes_rechazados = spark.read.format(\"csv\")\\\n",
    "                            .option(\"header\", \"true\")\\\n",
    "                            .option(\"inferSchema\", \"true\")\\\n",
    "                            .load(\"data/data_test/test_pacientes_rechazados.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agregamos columna aprobado en los df_pacientes_aprobados y df_pacientes_rechazados\n",
    "df_pacientes_aprobados = df_pacientes_aprobados.withColumn(\"aprobado\", func.lit(True))\n",
    "df_pacientes_rechazados = df_pacientes_rechazados.withColumn(\"aprobado\", func.lit(False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quitamos columnas sobrantes en df_pacientes_aprobados\n",
    "df_pacientes_aprobados = df_pacientes_aprobados.drop(\"fecha_admision\",\"fecha_desembolso\",\"grupo_diagnostico\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# damos el mismo formato de columna en df_pacientes_rechazados\n",
    "df_pacientes_rechazados = df_pacientes_rechazados.withColumn(\"deducible\", func.col(\"deducible\").cast(\"double\"))\n",
    "df_pacientes_rechazados = df_pacientes_rechazados.withColumn(\"procedimiento_v\", func.col(\"procedimiento_v\").cast(\"double\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ordenamos el df_pacientes_rechazados en el mismo orden de df_pacientes aprobados para realizar el union\n",
    "df_pacientes_rechazados = df_pacientes_rechazados.select(df_pacientes_aprobados.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creames el df_pacientes de la union de df_pacientes_aprobados con df_pacientes_rechazados\n",
    "df_pacientes = df_pacientes_aprobados.union(df_pacientes_rechazados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a cada paciente agregamos la informacion del beneficiario\n",
    "df_data = df_pacientes.join(df_beneficiario, on=[\"cod_beneficiario\"], how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se eliminan variables que no aportan\n",
    "df_data = df_data.drop(\"cod_beneficiario\",\n",
    "                       \"id_peticion\",\n",
    "                       \"fin_peticion\",\n",
    "                       \"inicio_peticion\",\n",
    "                       \"meses_parte_a\",\n",
    "                       \"meses_parte_b\",\n",
    "                       \"muerte\",\n",
    "                       \"nacimiento\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- aprovisionador: string (nullable = true)\n",
      " |-- deducible: double (nullable = true)\n",
      " |-- diagnostico_a: string (nullable = true)\n",
      " |-- diagnostico_admision: string (nullable = true)\n",
      " |-- diagnostico_b: string (nullable = true)\n",
      " |-- diagnostico_c: string (nullable = true)\n",
      " |-- diagnostico_d: string (nullable = true)\n",
      " |-- diagnostico_e: string (nullable = true)\n",
      " |-- diagnostico_f: string (nullable = true)\n",
      " |-- diagnostico_g: string (nullable = true)\n",
      " |-- diagnostico_h: string (nullable = true)\n",
      " |-- diagnostico_i: string (nullable = true)\n",
      " |-- diagnostico_j: string (nullable = true)\n",
      " |-- medico_atiende: string (nullable = true)\n",
      " |-- medico_operacion: string (nullable = true)\n",
      " |-- monto_reembolso: integer (nullable = true)\n",
      " |-- otros_medicos: string (nullable = true)\n",
      " |-- procedimiento_u: string (nullable = true)\n",
      " |-- procedimiento_v: double (nullable = true)\n",
      " |-- procedimiento_w: string (nullable = true)\n",
      " |-- procedimiento_x: string (nullable = true)\n",
      " |-- procedimiento_y: double (nullable = true)\n",
      " |-- procedimiento_z: double (nullable = true)\n",
      " |-- aprobado: boolean (nullable = false)\n",
      " |-- alzheimer: integer (nullable = true)\n",
      " |-- artritis_reumatoide: integer (nullable = true)\n",
      " |-- cancer: integer (nullable = true)\n",
      " |-- ciudad: integer (nullable = true)\n",
      " |-- corazon_isquemico: integer (nullable = true)\n",
      " |-- depresion: integer (nullable = true)\n",
      " |-- diabetes: integer (nullable = true)\n",
      " |-- enfermedad_renal: string (nullable = true)\n",
      " |-- genero: integer (nullable = true)\n",
      " |-- infarto_cerebral: integer (nullable = true)\n",
      " |-- ips_deducible_anual: integer (nullable = true)\n",
      " |-- ips_reembolso_anual: integer (nullable = true)\n",
      " |-- municipio: integer (nullable = true)\n",
      " |-- obstruccion_pulmonar: integer (nullable = true)\n",
      " |-- op_deducible_anual: integer (nullable = true)\n",
      " |-- op_reembolso_anual: integer (nullable = true)\n",
      " |-- osteoporosis: integer (nullable = true)\n",
      " |-- problemas_corazon: integer (nullable = true)\n",
      " |-- problemas_rinon: integer (nullable = true)\n",
      " |-- raza: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321 . connected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O cluster uptime:</td>\n",
       "<td>2 hours 11 mins</td></tr>\n",
       "<tr><td>H2O cluster timezone:</td>\n",
       "<td>America/Bogota</td></tr>\n",
       "<tr><td>H2O data parsing timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O cluster version:</td>\n",
       "<td>3.26.0.6</td></tr>\n",
       "<tr><td>H2O cluster version age:</td>\n",
       "<td>5 days </td></tr>\n",
       "<tr><td>H2O cluster name:</td>\n",
       "<td>H2O_from_python_josedavidarevaloespinosa_3nf42w</td></tr>\n",
       "<tr><td>H2O cluster total nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O cluster free memory:</td>\n",
       "<td>3.255 Gb</td></tr>\n",
       "<tr><td>H2O cluster total cores:</td>\n",
       "<td>4</td></tr>\n",
       "<tr><td>H2O cluster allowed cores:</td>\n",
       "<td>4</td></tr>\n",
       "<tr><td>H2O cluster status:</td>\n",
       "<td>locked, healthy</td></tr>\n",
       "<tr><td>H2O connection url:</td>\n",
       "<td>http://localhost:54321</td></tr>\n",
       "<tr><td>H2O connection proxy:</td>\n",
       "<td>None</td></tr>\n",
       "<tr><td>H2O internal security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>H2O API Extensions:</td>\n",
       "<td>Amazon S3, XGBoost, Algos, AutoML, Core V3, TargetEncoder, Core V4</td></tr>\n",
       "<tr><td>Python version:</td>\n",
       "<td>3.7.3 final</td></tr></table></div>"
      ],
      "text/plain": [
       "--------------------------  ------------------------------------------------------------------\n",
       "H2O cluster uptime:         2 hours 11 mins\n",
       "H2O cluster timezone:       America/Bogota\n",
       "H2O data parsing timezone:  UTC\n",
       "H2O cluster version:        3.26.0.6\n",
       "H2O cluster version age:    5 days\n",
       "H2O cluster name:           H2O_from_python_josedavidarevaloespinosa_3nf42w\n",
       "H2O cluster total nodes:    1\n",
       "H2O cluster free memory:    3.255 Gb\n",
       "H2O cluster total cores:    4\n",
       "H2O cluster allowed cores:  4\n",
       "H2O cluster status:         locked, healthy\n",
       "H2O connection url:         http://localhost:54321\n",
       "H2O connection proxy:\n",
       "H2O internal security:      False\n",
       "H2O API Extensions:         Amazon S3, XGBoost, Algos, AutoML, Core V3, TargetEncoder, Core V4\n",
       "Python version:             3.7.3 final\n",
       "--------------------------  ------------------------------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "h2o.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf = df_data.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "hdf = h2o.H2OFrame(pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cargamos el modelo para realizar la prediccion\n",
    "fraud_model = h2o.load_model(\"model_identify_fraudulent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reasignamos variables categoricas para el entrenamiento\n",
    "hdf[\"diagnostico_a\"] = hdf[\"diagnostico_a\"].asfactor()\n",
    "hdf[\"deducible\"] = hdf[\"deducible\"].asfactor()\n",
    "hdf[\"diagnostico_admision\"] = hdf[\"diagnostico_admision\"].asfactor()\n",
    "hdf[\"diagnostico_b\"] = hdf[\"diagnostico_b\"].asfactor()\n",
    "hdf[\"diagnostico_c\"] = hdf[\"diagnostico_c\"].asfactor()\n",
    "hdf[\"diagnostico_d\"] = hdf[\"diagnostico_d\"].asfactor()\n",
    "hdf[\"diagnostico_e\"] = hdf[\"diagnostico_e\"].asfactor()\n",
    "hdf[\"diagnostico_f\"] = hdf[\"diagnostico_f\"].asfactor()\n",
    "hdf[\"diagnostico_g\"] = hdf[\"diagnostico_g\"].asfactor()\n",
    "hdf[\"diagnostico_h\"] = hdf[\"diagnostico_h\"].asfactor()\n",
    "hdf[\"diagnostico_i\"] = hdf[\"diagnostico_i\"].asfactor()\n",
    "hdf[\"procedimiento_z\"] = hdf[\"procedimiento_z\"].asfactor()\n",
    "hdf[\"alzheimer\"] = hdf[\"alzheimer\"].asfactor()\n",
    "hdf[\"artritis_reumatoide\"] = hdf[\"artritis_reumatoide\"].asfactor()\n",
    "hdf[\"cancer\"] = hdf[\"cancer\"].asfactor()\n",
    "hdf[\"ciudad\"] = hdf[\"ciudad\"].asfactor()\n",
    "hdf[\"corazon_isquemico\"] = hdf[\"corazon_isquemico\"].asfactor()\n",
    "hdf[\"diabetes\"] = hdf[\"diabetes\"].asfactor()\n",
    "hdf[\"ciudad\"] = hdf[\"ciudad\"].asfactor()\n",
    "hdf[\"enfermedad_renal\"] = hdf[\"enfermedad_renal\"].asfactor()\n",
    "hdf[\"genero\"] = hdf[\"genero\"].asfactor()\n",
    "hdf[\"infarto_cerebral\"] = hdf[\"infarto_cerebral\"].asfactor()\n",
    "hdf[\"municipio\"] = hdf[\"municipio\"].asfactor()\n",
    "hdf[\"obstruccion_pulmonar\"] = hdf[\"obstruccion_pulmonar\"].asfactor()\n",
    "hdf[\"osteoporosis\"] = hdf[\"osteoporosis\"].asfactor()\n",
    "hdf[\"problemas_corazon\"] = hdf[\"problemas_corazon\"].asfactor()\n",
    "hdf[\"problemas_rinon\"] = hdf[\"problemas_rinon\"].asfactor()\n",
    "hdf[\"raza\"] = hdf[\"raza\"].asfactor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf[\"es_fraudulento\"] = fraud_model.predict(hdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
